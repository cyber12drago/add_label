{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "path_df = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/Pickles_title/df.pickle\"\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)\n",
    "\n",
    "# features_train\n",
    "path_features_train = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/Pickles_title/features_train.pickle\"\n",
    "with open(path_features_train, 'rb') as data:\n",
    "    features_train = pickle.load(data)\n",
    "\n",
    "# labels_train\n",
    "path_labels_train = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/Pickles_title/labels_train.pickle\"\n",
    "with open(path_labels_train, 'rb') as data:\n",
    "    labels_train = pickle.load(data)\n",
    "\n",
    "# features_test\n",
    "path_features_test = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/Pickles_title/features_test.pickle\"\n",
    "with open(path_features_test, 'rb') as data:\n",
    "    features_test = pickle.load(data)\n",
    "\n",
    "# labels_test\n",
    "path_labels_test = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/Pickles_title/labels_test.pickle\"\n",
    "with open(path_labels_test, 'rb') as data:\n",
    "    labels_test = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the dimension of our feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2676, 300)\n",
      "(473, 300)\n",
      "                                               title  \\\n",
      "0  \"Sebenarnya Saya Sudah Pesan Orkes, Sudah Kasi...   \n",
      "1  \"Update\" Berkala AI Bikin Alat Deteksi Covid-1...   \n",
      "2  1.190 Tenaga Kesehatan Bantu Penanganan Covid-...   \n",
      "3  1.262 Orang di Secapa TNI AD Bandung Positif C...   \n",
      "4  1.379.662 Kasus Covid-19 di Indonesia, PPKM Mi...   \n",
      "\n",
      "                                        title_parsed news_portal  \\\n",
      "0           pesan orkes  kasih uang muka nyata gagal      kompas   \n",
      "1  update  ai bikin alat deteksi  karya ugm genos...      kompas   \n",
      "2            tenaga sehat bantu tangan   jakarta      tribunnews   \n",
      "3   orang  capa tni ad bandung positif  warga   p...  tribunnews   \n",
      "4                           ppkm mikro klaim tekan        kompas   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://regional.kompas.com/read/2020/04/01/14...   \n",
      "1  https://regional.kompas.com/read/2020/12/30/07...   \n",
      "2  https://www.tribunnews.com/metropolitan/2020/0...   \n",
      "3  https://www.tribunnews.com/corona/2020/07/10/1...   \n",
      "4  https://nasional.kompas.com/read/2021/03/08/05...   \n",
      "\n",
      "                                             img_url        date  \\\n",
      "0  https://asset.kompas.com/crops/KX0cYSp6XFrs-Jt...  2020-04-01   \n",
      "1  https://asset.kompas.com/crops/dspupYKGzyRECRL...  2020-12-30   \n",
      "2  https://cdn-2.tstatic.net/tribunnews/foto/bank...  2020-09-04   \n",
      "3  https://cdn-2.tstatic.net/tribunnews/foto/bank...  2020-07-10   \n",
      "4  https://asset.kompas.com/crops/29iuLluQH9j1eu_...  2021-03-08   \n",
      "\n",
      "                                             content  \\\n",
      "0  - Zaenal Abidin harus menggelar resepsi pernik...   \n",
      "1  - Alat deteksi Covid-19 lewat embusan napas ya...   \n",
      "2  Â   Sebanyak 1.190   profesional lolos seleksi ...   \n",
      "3   Suasana terkini di Sekolah Calon Perwira TNI ...   \n",
      "4  - Pandemi sudah satu tahun melanda Indonesia ....   \n",
      "\n",
      "                                                 tag                 area  \\\n",
      "0  Lombok Tengah, ntb positif covid-19, kasus cor...  nusa tenggara barat   \n",
      "1  UGM, Yogyakarta, GeNose, alat deteksi covid Ge...        di_yogyakarta   \n",
      "2  runing news, Covid-19, tenaga kesehatan, Jakar...          dki jakarta   \n",
      "3  Secapa TNI AD, Secapa AD Bandung, Running News...           jawa barat   \n",
      "4  vaksinasi, Covid-19, Satuan Tugas Penanganan C...            indonesia   \n",
      "\n",
      "            kota                        label  label_code  \n",
      "0  lombok tengah                    criticism           2  \n",
      "1     yogyakarta  notification of information           0  \n",
      "2            NaN                     donation           1  \n",
      "3        bandung                    criticism           2  \n",
      "4            NaN                         hoax           3  \n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can see what hyperparameters the model has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 8,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf_0 = RandomForestClassifier(random_state = 8)\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf_0.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll tune the following ones:\n",
    "\n",
    "* `n_estimators` = number of trees in the forest.\n",
    "* `max_features` = max number of features considered for splitting a node\n",
    "* `max_depth` = max number of levels in each decision tree\n",
    "* `min_samples_split` = min number of data points placed in a node before the node is split\n",
    "* `min_samples_leaf` = min number of data points allowed in a leaf node\n",
    "* `bootstrap` = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [20, 40, 60, 80, 100, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000]}\n"
     ]
    }
   ],
   "source": [
    "# n_estimators\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)]\n",
    "\n",
    "# max_features\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max_depth\n",
    "max_depth = [int(x) for x in np.linspace(20, 100, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# min_samples_split\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# min_samples_leaf\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# bootstrap\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll perform the Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "# First create the base model to tune\n",
    "rfc = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=rfc,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=4, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the best hyperparameters resulting from the Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can do a more exhaustive search centered in those values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=8, test_size=0.33, train_size=None),\n",
       "             estimator=RandomForestClassifier(random_state=8),\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [70, 80, 90],\n",
       "                         'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [800]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "bootstrap = [True]\n",
    "max_depth = [70, 80, 90]\n",
    "max_features = ['auto']\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "min_samples_split = [5, 10, 15]\n",
    "n_estimators = [800]\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': bootstrap,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'n_estimators': n_estimators\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rfc = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rfc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameters turn out to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 70, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 15, 'n_estimators': 800}\n",
      "0.926470588235294\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model in `best_rfc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rfc =  grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know the best random forest model. Let's fit it and see how it performs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit the model to our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=70, min_samples_split=15, n_estimators=800,\n",
       "                       random_state=8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = best_rfc.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional class probabilities can be obtained by typing:\n",
    "\n",
    "`rfc_pred = best_rfc.predict_proba(features_test)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance analysis, we will use the confusion matrix, the classification report and the accuracy on both training and test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.9786995515695067\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, best_rfc.predict(features_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: \n",
      "0.945031712473573\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       226\n",
      "           1       0.98      0.95      0.96        86\n",
      "           2       0.82      0.88      0.85        73\n",
      "           3       0.89      0.85      0.87        88\n",
      "\n",
      "    accuracy                           0.95       473\n",
      "   macro avg       0.92      0.92      0.92       473\n",
      "weighted avg       0.95      0.95      0.95       473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-b0f1d91c83fb>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-b0f1d91c83fb>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    xticklabels=aux_df['label']http://localhost:8888/notebooks/Documents/PBA/Tugas%20Akhir/Untitled%20Folder/04.%20Model%20Training/06.%20MT%20-%20Random%20Forest.ipynb.values,\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "aux_df = df[['label', 'label_code']].drop_duplicates().sort_values('label_code')\n",
    "conf_matrix = confusion_matrix(labels_test, rfc_pred)\n",
    "plt.figure(figsize=(12.8,6))\n",
    "aux_df['label'].values[0]='Informasi'\n",
    "aux_df['label'].values[1]='Donasi'\n",
    "aux_df['label'].values[2]='Kritik'\n",
    "aux_df['label'].values[3]='Hoaks'\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            xticklabels=aux_df['label'].values, \n",
    "            yticklabels=aux_df['label'].values,\n",
    "            cmap=\"Blues\", fmt='.2f')\n",
    "plt.ylabel('Prediksi')\n",
    "plt.xlabel('Aktual')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we could get the average time the model takes to get predictions. We want the algorithm to be fast since we are creating an app which will gather data from the internet and get the predicted categories. However, since the difference when predicting 10-20 observations will be very little, we won't take this into account.\n",
    "\n",
    "However, the code below could do this task:\n",
    "\n",
    "```python\n",
    "features_time = features_train\n",
    "elapsed_list = []\n",
    "for i in range(0,10):\n",
    "    \n",
    "    start = time.time()\n",
    "    predictions = best_lrc.predict(features_time)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    elapsed_list.append(elapsed)\n",
    "\n",
    "mean_time_elapsed = np.mean(elapsed_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the hyperparameter tuning process has returned a better model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9429175475687104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(random_state = 8)\n",
    "base_model.fit(features_train, labels_train)\n",
    "accuracy_score(labels_test, base_model.predict(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945031712473573"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc.fit(features_train, labels_train)\n",
    "accuracy_score(labels_test, best_rfc.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a dataset with a model summary to compare models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "     'Model': 'Random Forest',\n",
    "     'Training Set Accuracy': accuracy_score(labels_train, best_rfc.predict(features_train)),\n",
    "     'Test Set Accuracy': accuracy_score(labels_test, rfc_pred)\n",
    "}\n",
    "\n",
    "df_models_rfc = pd.DataFrame(d, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.945032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Training Set Accuracy  Test Set Accuracy\n",
       "0  Random Forest                 0.9787           0.945032"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model and this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Models/best_rfc.pickle', 'wb') as output:\n",
    "    pickle.dump(best_rfc, output)\n",
    "    \n",
    "with open('Models/df_models_rfc.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_rfc, output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "path_df = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/03. Feature Engineering/Pickles_title/df.pickle\"\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)\n",
    "    \n",
    "# X_train\n",
    "path_X_train = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/03. Feature Engineering/Pickles_title/X_train.pickle\"\n",
    "with open(path_X_train, 'rb') as data:\n",
    "    X_train = pickle.load(data)\n",
    "\n",
    "# X_test\n",
    "path_X_test = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/03. Feature Engineering/Pickles_title/X_test.pickle\"\n",
    "with open(path_X_test, 'rb') as data:\n",
    "    X_test = pickle.load(data)\n",
    "\n",
    "# y_train\n",
    "path_y_train = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/03. Feature Engineering/Pickles_title/y_train.pickle\"\n",
    "with open(path_y_train, 'rb') as data:\n",
    "    y_train = pickle.load(data)\n",
    "\n",
    "# y_test\n",
    "path_y_test = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/Untitled Folder/03. Feature Engineering/Pickles_title/y_test.pickle\"\n",
    "with open(path_y_test, 'rb') as data:\n",
    "    y_test = pickle.load(data)\n",
    "\n",
    "# features_train\n",
    "path_features_train = \"C:/Users/asus-pc/Documents/PBA/Untitled Folder/Tugas Akhir/03. Feature Engineering/Pickles_title/features_train.pickle\"\n",
    "with open(path_features_train, 'rb') as data:\n",
    "    features_train = pickle.load(data)\n",
    "\n",
    "# labels_train\n",
    "path_labels_train = \"C:/Users/asus-pc/Documents/PBA/Untitled Folder/Tugas Akhir/03. Feature Engineering/Pickles_title/labels_train.pickle\"\n",
    "with open(path_labels_train, 'rb') as data:\n",
    "    labels_train = pickle.load(data)\n",
    "\n",
    "# features_test\n",
    "path_features_test = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/03. Feature Engineering/Pickles_title/features_test.pickle\"\n",
    "with open(path_features_test, 'rb') as data:\n",
    "    features_test = pickle.load(data)\n",
    "\n",
    "# labels_test\n",
    "path_labels_test = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/03. Feature Engineering/Pickles_title/labels_test.pickle\"\n",
    "with open(path_labels_test, 'rb') as data:\n",
    "    labels_test = pickle.load(data)\n",
    "    \n",
    "# SVM Model\n",
    "path_model = \"C:/Users/asus-pc/Documents/PBA/Tugas Akhir/04. Model Training/Models/best_RFC.pickle\"\n",
    "with open(path_model, 'rb') as data:\n",
    "    svc_model = pickle.load(data)\n",
    "    \n",
    "# Category mapping dictionary\n",
    "category_codes = {\n",
    "    'notification of information': 0,\n",
    "    'donation': 1,\n",
    "    'criticism': 2,\n",
    "    'hoax': 3,\n",
    "}\n",
    "\n",
    "category_names = {\n",
    "    0: 'notification of information',\n",
    "    1: 'donation',\n",
    "    2: 'criticism',\n",
    "    3: 'hoax'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svc_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes of the test set\n",
    "index_X_test = X_test.index\n",
    "\n",
    "# We get them from the original df\n",
    "df_test = df.loc[index_X_test]\n",
    "\n",
    "# Add the predictions\n",
    "df_test['prediction'] = predictions\n",
    "\n",
    "# Clean columns\n",
    "df_test = df_test[['title', 'label', 'label_code', 'prediction']]\n",
    "\n",
    "# Decode\n",
    "df_test['label_predicted'] = df_test['prediction']\n",
    "df_test = df_test.replace({'label_predicted':category_names})\n",
    "\n",
    "# Clean columns again\n",
    "df_test = df_test[['title', 'label', 'label_predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>label_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>Update Corona Indonesia 24 Oktober 2020 dan Se...</td>\n",
       "      <td>notification of information</td>\n",
       "      <td>notification of information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>Pertamina Diminta Lihat Fluktuasi Harga Minyak...</td>\n",
       "      <td>criticism</td>\n",
       "      <td>criticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>UPDATE 17 Januari: Ada 145.482 Kasus Aktif Cov...</td>\n",
       "      <td>notification of information</td>\n",
       "      <td>notification of information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Sebaran 4.002 Kasus Positif Hari Ini, DKI-Jaba...</td>\n",
       "      <td>donation</td>\n",
       "      <td>donation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>UPDATE Corona 31 Maret di 32 Provinsi: Kasus B...</td>\n",
       "      <td>notification of information</td>\n",
       "      <td>notification of information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "2182  Update Corona Indonesia 24 Oktober 2020 dan Se...   \n",
       "1279  Pertamina Diminta Lihat Fluktuasi Harga Minyak...   \n",
       "1729  UPDATE 17 Januari: Ada 145.482 Kasus Aktif Cov...   \n",
       "1477  Sebaran 4.002 Kasus Positif Hari Ini, DKI-Jaba...   \n",
       "1964  UPDATE Corona 31 Maret di 32 Provinsi: Kasus B...   \n",
       "\n",
       "                            label              label_predicted  \n",
       "2182  notification of information  notification of information  \n",
       "1279                    criticism                    criticism  \n",
       "1729  notification of information  notification of information  \n",
       "1477                     donation                     donation  \n",
       "1964  notification of information  notification of information  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>label_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>Satgas Covid-19 dan Polda Jabar Diminta Panggi...</td>\n",
       "      <td>criticism</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Buntut Kasus Kerumunan Massa Rizieq Shihab: Gi...</td>\n",
       "      <td>criticism</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>UPDATE Lengkap 5 Fakta Warga Depok Positif Vir...</td>\n",
       "      <td>hoax</td>\n",
       "      <td>notification of information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Kominfo Catat Ada 2 Ribu Lebih Konten Hoax Ten...</td>\n",
       "      <td>hoax</td>\n",
       "      <td>criticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>Polri Tidak Berikan Izin Keramaian Pelaksanaan...</td>\n",
       "      <td>donation</td>\n",
       "      <td>criticism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title      label  \\\n",
       "1454  Satgas Covid-19 dan Polda Jabar Diminta Panggi...  criticism   \n",
       "360   Buntut Kasus Kerumunan Massa Rizieq Shihab: Gi...  criticism   \n",
       "2772  UPDATE Lengkap 5 Fakta Warga Depok Positif Vir...       hoax   \n",
       "945   Kominfo Catat Ada 2 Ribu Lebih Konten Hoax Ten...       hoax   \n",
       "1324  Polri Tidak Berikan Izin Keramaian Pelaksanaan...   donation   \n",
       "\n",
       "                  label_predicted  \n",
       "1454                         hoax  \n",
       "360                          hoax  \n",
       "2772  notification of information  \n",
       "945                     criticism  \n",
       "1324                    criticism  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (df_test['label'] != df_test['label_predicted'])\n",
    "\n",
    "df_misclassified = df_test[condition]\n",
    "df_misclassified.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_article(row_article):\n",
    "    print('Actual Category: %s' %(row_article['label']))\n",
    "    print('Predicted Category: %s' %(row_article['label_predicted']))\n",
    "    print('-------------------------------------------')\n",
    "    print('Text: ')\n",
    "    print('%s' %(row_article['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[360, 3019, 1119]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed()\n",
    "list_samples = random.sample(list(df_misclassified.index), 3)\n",
    "list_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Category: criticism\n",
      "Predicted Category: hoax\n",
      "-------------------------------------------\n",
      "Text: \n",
      "Buntut Kasus Kerumunan Massa Rizieq Shihab: Gibran Disinggung, Pejabat Dipanggil, Kapolda Dicopot\n"
     ]
    }
   ],
   "source": [
    "output_article(df_misclassified.loc[list_samples[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Category: donation\n",
      "Predicted Category: criticism\n",
      "-------------------------------------------\n",
      "Text: \n",
      "Vaksin Covid-19 Batch 1 Kedaluwarsa 25 Maret, Bio Farma Pastikan Sudah Diberikan Kepada Nakes\n"
     ]
    }
   ],
   "source": [
    "output_article(df_misclassified.loc[list_samples[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Category: donation\n",
      "Predicted Category: criticism\n",
      "-------------------------------------------\n",
      "Text: \n",
      "Narapidana Sumbangkan Hasil Karyanya untuk Penanganan Corona di Indonesia\n"
     ]
    }
   ],
   "source": [
    "output_article(df_misclassified.loc[list_samples[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
